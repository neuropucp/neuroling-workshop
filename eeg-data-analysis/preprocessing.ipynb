{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","collapsed":true,"id":"ulyoieAbTRHm"},"outputs":[],"source":["#@title Black Box_(install libraries)\n","%%capture\n","!pip install pingouin\n","!pip install autoreject\n","!pip install mne\n","!pip install mne_bids\n","!pip install mne_icalabel\n","!pip install pyprep\n","!pip install onnxruntime\n","!pip install python-picard\n","!pip install ipywidgets\n","!pip install IPhyton\n","!apt-get -qq update\n","!apt-get -qq install tree"]},{"cell_type":"markdown","metadata":{"id":"ywQjHi2bhpPO"},"source":["Hola!\n","\n","<br>\n","\n","Este tutorial tendrá como objetivo enseñar un flujo de análisis para Potenciales Relacionados a Eventos y Time Frequency Analysis.\n","\n","<br>\n","\n","Los datos que utilizaremos para contextualizar los cálculos son del paper:\n","\n","\n","> Isasi-Isasmendi, A., Sauppe, S., Andrews, C., Laka, I., Meyer, M., & Bickel, B. (2024). Incremental sentence processing is guided by a preference for agents: EEG evidence from Basque. Language, Cognition and Neuroscience, 39(1), 76-97.\n","\n","<br>\n","\n","Obtenidos mediante el <a href=\"https://osf.io/6gjkz/files\"\n","  target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","  repositorio\n","  </a> abierto en el cual se ha publicado. Parte del flujo de pre procesamiento intentará replicar las decisiones que tomaron los investigadores mediante las herramientas disponibles en Python. Sin embargo, en algún momento diferiremos del original por motivos de simplificación para la demostración.\n","\n","<br>\n","\n","A grandes rasgos, el procesamiento de EEG tiene este flujo.\n","\n","\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_01.png\"\n","       alt=\"montaje\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Flujo general.</figcaption>\n","</figure>\n","\n","\n","<br>\n","\n","En este tutorial nos centraremos en la etapa más concentrada en el pre procesamiento de datos.\n","\n","<br>\n","\n","A lo largo del tutorial, podremos encontrar bloques de código con el texto \"Ｂｌａｃｋ　Ｂｏｘ\". Estos bloques de código sólo están pensados para ser ejecutados. Más allá de esbozar una idea general o conceptual, no explicaremos lo que sucede dentro de las cajas negras, pero ejecutarlas es necesario para poder seguir con la experiencia."]},{"cell_type":"code","source":["#@title Example BlackBox\n","\n","import ipywidgets\n","\n","\n","# Variables\n","PASSWORD_1 = \"ciencia\"\n","PASSWORD_2 = \"curiosidad\"\n","IMG_URL_1 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Black_box_diagram.svg/1920px-Black_box_diagram.svg.png\"\n","IMG_URL_2 = \"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/06_ai.png\"\n","output=ipywidgets.Output()\n","\n","# 1st\n","pwd1 = ipywidgets.Password(\n","    description='Password：',\n","    placeholder=\"¿Qué abre la caja negra?\",\n","    continuous_update=True,\n","    layout=ipywidgets.Layout(width='300px')\n","    )\n","\n","\n","# 2nd\n","pwd2 = ipywidgets.Password(\n","    description='Ｐａｓｓｗｏｒｄ：',\n","    placeholder=\"\",\n","    continuous_update=True,\n","    layout=ipywidgets.Layout(width='300px')\n","    )\n","\n","pwd2.layout.display = \"none\"\n","\n","# img\n","img = ipywidgets.HTML(value=f'<img src=\"{IMG_URL_1}\" width=\"600\">')\n","img.layout.display = \"none\"\n","\n","# manejo del primer password\n","def on_pwd1(change):\n","    if change['name'] == 'value' and change['new'] == PASSWORD_1:\n","        with output:\n","           output.clear_output()\n","           print(\"Ｗｈａｔ ｒｅａｌｌｙ　ｏｐｅｎｓ　ｔｈｅ　Ｂｌａｃｋ　Ｂｏｘ？\")\n","        img.layout.display = \"block\"\n","        pwd2.layout.display = \"block\"\n","        pwd1.layout.display = \"none\"\n","        pwd1.unobserve(on_pwd1, names=\"value\")\n","\n","# manejo del segundo password\n","def on_pwd2(change):\n","    if change['name'] == 'value' and change['new'] == PASSWORD_2:\n","        with output:\n","          output.clear_output()\n","          print(\"\")\n","        img.value = f'<img src=\"{IMG_URL_2}\" width=\"600\">'\n","        pwd2.unobserve(on_pwd2, names=\"value\")\n","        pwd2.layout.display = \"none\"\n","\n","# activate observs\n","pwd1.observe(on_pwd1, names=\"value\")\n","pwd2.observe(on_pwd2, names=\"value\")\n","\n","\n","display(pwd1, img, pwd2, output)\n","\n"],"metadata":{"cellView":"form","id":"bkX8-qTPkbl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjB03YnbTEEM"},"outputs":[],"source":["#@title Import modules\n","\n","%%capture\n","import autoreject\n","import ipywidgets\n","import matplotlib.pyplot as plt\n","import mne\n","import mne_bids\n","import mne_icalabel\n","import numpy as np\n","import os\n","import pandas as pd\n","import pyprep\n"]},{"cell_type":"markdown","metadata":{"id":"gENu-dV_hLmT"},"source":["| Paquete                | Descripción                                                                 |\n","|------------------------|-----------------------------------------------------------------------------|\n","| autoreject           | Librería para la detección automática de artefactos en los datos de EEG mediante el algoritmo de AutoReject. |\n","| ipywidgets                    | Widgets para algunas de nuestras ＢｌａｃｋＢｏｘ. |\n","| matplotlib                    | Crear visualizaciones estáticas, animadas e interactivas. Librería fundamental de otras que también generan gráficos. |\n","| mne                    | Librería para el análisis de datos de EEG, MEG y otros tipos de datos para neurociencia computacional. |\n","| mne-bids               | Extensión de MNE para manejar datos en formato BIDS. |\n","| mne-icalabel           | Un algoritmo entrenado para etiquetar automáticamente componentes encontrados mediante un Independent Component Analysis (ICA). |\n","| numpy           | Librería base para trabajar matemáticamente con arrays de datos. Es la base de pandas y muchas otras librerías que usamos. |\n","| os           | Módulo de Python para interactuar con las rutas del sistema operativo. |\n","| pandas           | Librería fundamental para la computación e interacción de datos estructurados (matrices). |\n","| pyprep           | Permite utilizar el pipeline PREP en Python para rechazar electrodos y mejorar la señal EEG. |"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"sIhq0lJzapNy"},"outputs":[],"source":["#@title Black Box_(download data in BIDS format)\n","#%%capture\n","!wget \"https://drive.usercontent.google.com/download?id=1wwNiWnMGSvVJ25FnVXJ3t7M58mSgWwgB&export=download&confirm\" -O BIDS.zip\n","!unzip -o BIDS.zip"]},{"cell_type":"markdown","metadata":{"id":"bgSWU-pMNPNZ"},"source":["# ¿Qué es MNE Python?\n","\n","MNE es una librería que brinda herramientas para analizar datos neuofisiológicos.  \n","\n","Es una herramienta gratuita, pues se construye dentro del marco de la **Open Science**\n","\n","Los datos que MNE permite analizar con sus funciones son: MEG, EEG, fMRI, sEEG, ECoG, NIRS, eyetracking; entre muchos otros."]},{"cell_type":"markdown","metadata":{"id":"aopRsc81OcSc"},"source":["Desde que ejecutamos el módulo para importar los datos, ya nos podemos percatar de que tiene una palabra extraña: **\"BIDS\"**.  \n","\n","Estas siglas pertenecen a las palabras: **Brain Imaging Data Structure.**  \n","<br><br>\n","<center>\n","\n","> <em>¿Profe... por qué tener un estándar para organizar data?  \n","¿No puedo analizarla como quiera?</em>  \n","  \n","\n","</center>\n","<br><br>\n","\n","En realidad, sí. Estamos en lo cierto en pensar que podemos organizar **nuestra data** como queramos, hacer cálculos y llegar a conclusiones sin ninguna dificultad. Sin embargo\n","\n","<br><br>\n","\n","<center>\n","\n","\n","---\n","\n","<br>\n","\n","¿Cómo podemos evaluar la certeza de algo que **solamente nosotros** sabemos?\n","\n","<br>\n","\n","---\n","\n","\n","</center>\n","<br><br>\n","\n","\n","\n","Pues aquí es donde entra el BIDS.  \n","<br>\n","Dentro de la ciencia abierta, cualquiera **debe** tener el derecho de cuestionar; no solamente por una razón comunitaria, sino intelectual, ya que nuestros hallazgos sólo pueden pulir su validez mediante el cuestionamiento constante.   \n","<br>\n","Así, compartir los datos de manera menos críptica y más clara para hacer ciencia, lleva a que tengamos que desarrollar una convención para su organización.\n","<br>  \n","Más allá de la programación, como la estructura es una iniciativa en el marco la ciencia abierta, existen también distintas <a href=\"https://brainlife.io/docs/using_ezBIDS/\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      herramientas</a> más user-friendly para quien empieza a organizar los datos en formato BIDS.\n","\n","<br>  \n","\n","BIDS es la convención que usan bases de datos públicas como:  \n","\n","\n","<a href=\"https://openneuro.org/\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      **Open Neuro**\n","  </a>\n","\n","\n","<a href=\"https://www.neuroinfo.org/gsp\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      **Brain Genomics Superstruct Project**\n","  </a>\n","\n","<a href=\"https://www.ebrains.eu/\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      **Ebrains**\n","  </a>\n","\n","<a href=\"https://brainlife.io/about/\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      **Brainlife**\n","  </a>\n","\n","\n","Y más."]},{"cell_type":"markdown","metadata":{"id":"7AtpKvfqaBh9"},"source":["<h1>Base de datos normal Vs BIDS</h1>\n","<figure style=\"text-align:center; margin: 1.25rem 0;\">\n","  <img src=\"https://bids.neuroimaging.io/assets/img/dicom-reorganization-transparent-white_1000x477.png\"\n","       alt=\"Dataset EEG-BIDS\"\n","       style=\"display:block; margin:0 auto; max-width:100%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Reorganización DICOM → BIDS.</figcaption>\n","</figure>\n","\n","<h1>¿Qué hay dentro de cada archivo?</h1>\n","<figure style=\"text-align:center; margin: 1.25rem 0;\">\n","  <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-019-0104-8/MediaObjects/41597_2019_104_Fig1_HTML.png\"\n","       alt=\"Dataset EEG-BIDS\"\n","       style=\"display:block; margin:0 auto; max-width:100%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Estructura interna de un dataset BIDS.</figcaption>\n","</figure>\n","\n","\n","\n","\n","\n","Incluso ¡Podríamos intentar descargar una base de datos BIDS con sólo un click!\n","```\n","!pip install openneuro-py\n","on.download(\n","    dataset='ds004284', # OpenNeuro Accession Number\n","    target_dir='/content/data',  # Carpeta donde se guardará el dataset\n","    include=['sub-104/']  # Solo incluir los participantes sub-104\n",")\n","```\n","\n","Pero esto es una caja negra para otra historia..."]},{"cell_type":"markdown","metadata":{"id":"xDwcZ2jbd08z"},"source":["# Nuestros datos BIDS.\n","\n","\n","Como mencionamos anteriormente, los datos que hemos descargado son datos formateados en BIDS, pertenecientes al paper:\n","\n","> Isasi-Isasmendi, A., Sauppe, S., Andrews, C., Laka, I., Meyer, M., & Bickel, B. (2024). Incremental sentence processing is guided by a preference for agents: EEG evidence from Basque. Language, Cognition and Neuroscience, 39(1), 76-97.\n","\n","\n","\n","\n","\n","Cuya base de datos completa se encuentra disponible en   <a href=\"https://osf.io/6gjkz/files\"\n","  target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","  Open Science Framework\n","  </a>  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTTLU1BC7Tdv"},"outputs":[],"source":["!tree \"bids\" -L 4"]},{"cell_type":"markdown","metadata":{"id":"6j0YOEDDfitJ"},"source":["Para leer todos estos archivos, utilizaremos en conjunto las librerías de \"os\" (para navegar entre directorios) y MNE-BIDS.  \n","\n","En específico, invocaremos la función ```mne_bids.find_matching_paths```, con palabras que le indicarán qué información leer/revisar.  \n","\n","<br>\n","\n","Las dos funciones de \"os\" nos servirán para armar la ruta hacia nuestro experimento.\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: os.getcwd\n","  <a href=\"https://docs.python.org/3/library/os.html#os.getcwd\"\n","  target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","  [docs]\n","  </a>  \n","  \n","  </th></tr>\n","  <td>\n","  Obtiene y retorna la dirección del directorio en el se ejecuta la función. Básicamente, nos dice la dirección (path) en la que nos encontramos.\n","  </td>\n","</table>\n","\n","<br>\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: os.path.join\n","  <a href=\"https://docs.python.org/3/library/os.path.html#os.path.join\"\n","  target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","  [docs]\n","  </a>\n","</th></tr>\n","  <td>\n","  Sirve para unir rutas en formato de string. Tendremos que unir la dirección del directorio actual más \"bids/exp\".\n","  </td>\n","  </tr>\n","</table>\n","\n","\n","<br>\n","\n","Sin embargo, lo que realmente tendrá poder aquí para escanear todos los archivos eeg en formato BIDS posibles, es ```mne_bids.find_matching_paths```:\n","\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne_bids.find_matching_paths</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/mne-bids/stable/generated/mne_bids.find_matching_paths.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","  <tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","  <tr><td>root</td><td>Lugar (dirección del directorio) desde el que queremos que se busquen rutas BIDS</td></tr>\n","  <tr><td>subjects</td><td>El \"ID\" del sujeto. Es numérico (si es \"sub-24\", solo se coloca \"24\"). Recibe valores singulares o listas de varios valores</td></tr>\n","  <tr><td>tasks</td><td>Tarea experimental. Por ejemplo: 'oddball', 'SART'.</td></tr>\n","  <tr><td>datatypes</td><td>Tipos de datos que guarda el formato BIDS. Por ejemplo: 'anat', 'func', 'eeg', 'meg', 'ieeg'. </td></tr>\n","  <tr><td>extensions</td><td>Extensión de los archivos que queremos que busque. Por ejemplo: '.edf', '.vhdr'. Varía según el aparato que se usó.</td></tr>\n","  <tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","  <td colspan=\"2\">\n","  Lista de objetos BIDSPath. Estos objetos contienen la ruta al archivo eeg y además información adicional acerca del id del sujeto, task, etc.\n","  </td>\n","</table>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ex9CEKboTLYD"},"outputs":[],"source":["paths = mne_bids.find_matching_paths(\n","                            root=os.path.join(os.getcwd(), 'bids/exp'), #La carpeta a revisar\n","                            subjects=['01', '02', '04', '05', '23'], # ¿Qué sujetos queremos leer?\n","                            #tasks=, # No utilizaremos este argumento. Por default, al ignorarlo señala todas las task del experimento.\n","                            datatypes='eeg', #¿Qué tipo de dato hay que leer? BIDS se utiliza también para meg, fmri. Hay que especificar.\n","                            extensions='.vhdr' # este archivo apunta a los demás (Vision HeaDeR)\n","                            )\n","print(f\"Al final, creamos una lista de objetos 'BIDSPath', es decir, rutas de BIDS:\\n{paths}\")"]},{"cell_type":"markdown","metadata":{"id":"bivBzikUiQju"},"source":["<h2>Leer varios archivos en bucle</h2>\n","\n","Bien, ya tenemos las rutas en las cuales se encuentran los archivos, ahora sólo falta leerlos mediante la función de MNE-BIDS. Para eso haremos una iteración en el objeto <code>paths</code>, recuperarmos los BIDSPath y se leerán con la función:\n","``` mne_bids.read_raw_bids ```\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne_bids.read_raw_bids</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/mne-bids/stable/generated/mne_bids.read_raw_bids.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>bids_path</td><td>Objeto BIDSPath, que contiene la ruta (path) e información adicional</td></tr>\n","<tr><td>extra_params</td><td>Parámetros extra de la función que internamente se usa para leer los archivos:      <a href=\"https://mne.tools/stable/generated/mne.io.read_raw.html\"\n","      target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","    mne.io.read_raw</a>. Los parámetros adicionales se tendrán que pasar en forma de diccionario. Nosotros usaremos {'preload':True}\n","</td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto leído con MNE-Python de tipo: <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html\"\n","      target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","    mne.io.raw</a>. Se le denomina objeto 'raw', porque no ha recibido ningún cambio de pre procesado. Es la señal de EEG.\n","</td>\n","</table>\n","\n","<br>\n","\n","Todos los objetos leídos los almacenaremos en un diccionario llamado <code>original_eeg</code>, el cual crearemos primero. Las keys del diccionario serán los id de los participantes, y los values serán los objetos EEG/'Raw'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-oOdcU9p2Ax"},"outputs":[],"source":["##Iteramos por cada elemento en la lista (path) para leer el archivo\n","original_eeg ={}\n","for path in paths:\n","    raw = mne_bids.read_raw_bids(path, extra_params= {\n","        'preload': True #este parametro nos permite leer toda la data en la memoria RAM. Necesario para hacer cálculos de filtrado.\n","        })\n","    sub = path.subject # obtenemos la información del sujeto. Este es un método del objeto BIDSPath. Se obtiene como número de ID.\n","    original_eeg[sub] = raw  #guardaremos el archivo eeg en un diccionario, que tiene como clave el sujeto y como valor el archivo eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGXSNYtjOI63"},"outputs":[],"source":["display(original_eeg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qnv7YaXHOI65"},"outputs":[],"source":["display(original_eeg['01'])"]},{"cell_type":"markdown","metadata":{"id":"bk-fPPzeisHg"},"source":["¡Bien!\n","\n","<br>\n","\n","Ya tenemos los archivos EEG. El que estén en BIDS nos facilitó bastante saber dónde encontrar cada participante y su archivo asociado. Pudimos leer 5 participantes en una sola llamada.\n","\n","<br>\n","\n","Ahora, podríamos quedarnos explorando por largo rato todas las posibilidades que existen a este nivel, aún sin pre procesar.  \n","\n","<br>\n","\n","Quizá la más importante, antes de empezar a limpiar la data, es elegir un mapa de ubicación para los electrodos.  \n","\n","<br>\n","\n","<center>\n","\n"," <em>\n","\n","> ¿Cómo así profe? ¿Puedo elegir dónde se colocan los electrodos? ¿Eso no dependía del experimento?\n","\n"," </em>\n","\n","\n","</center>\n","\n","<br>\n","\n","En realidad, sí. El experimento es algo que ya sucedió, pero a nivel de datos, todavía MNE no sabe qué ubicación espacial (montaje) tuvieron, pues hay tantos tipos de electroencefalogramas que existen distintos mapas.  \n","\n","<br>\n","\n","Para nuestra suerte, los científicos precedentes ya definieron convenciones por nosotros. El montaje \"1020\" es el que fue elegido en el paper en cuestión.\n","\n","<figure style=\"text-align:center; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/70/21_electrodes_of_International_10-20_system_for_EEG.svg\"\n","       alt=\"montaje\"\n","       style=\"display:block; margin:0 auto; max-width:100%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Montaje 1020.</figcaption>\n","</figure>\n","\n","Utilizaremos entonces las funciones de MNE para obtener la información del montaje 1020 y aplicarla a nuestros electrodos. Primero, podemos empezar viendo qué montajes disponibles tiene MNE para ser aplicados. Para ello, se utilizará la función <code>mne.channels.get_builtin_montages</code>\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne.channels.get_builtin_montages</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.channels.get_builtin_montages.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>descriptions</td><td>False o True. Describe o no la lista de montajes que retorna</td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Lista de montajes que se pueden aplicar en MNE Python. Son únicamente nombres o strings de texto.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7UzDMe8w3hu"},"outputs":[],"source":["mne.channels.get_builtin_montages(descriptions=True)"]},{"cell_type":"markdown","metadata":{"id":"e4i0eAFOv9tM"},"source":["¡Genial!  \n","\n","<br>\n","\n","Sabemos que el montaje <code>'standart_1020'</code> está disponible. Los montajes en MNE son objetos que en esencia son imágenes, pero que tienen atributos para ser manipulados y así agregar o quitar canales. Entonces, para crear este tipo de objeto, tendremos que utilizar la función <code>mne.channels.make_standard_montage</code> y guardar su output.\n","\n","<br>\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne.channels.make_standard_montage</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.channels.make_standard_montage.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>kind</td><td>Tipo de montaje que queremos crear. En este caso \"standard_1020\"</td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto tipo       <a href=\"https://mne.tools/stable/generated/mne.channels.DigMontage.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      DigMontage</a>. Es una figura con atributos.\n","</table>\n","\n","<br>\n","\n","Al crear y guardar el objeto del montaje, lo que faltaría sería aplicarlo. Para ello iteraremos entre cada objeto eeg/'raw' que se acaba de leer y guardar en el diccionario. Un método de esos objetos es `.set_montage`, el cual nos permitirá aplicar el montaje que hemos creado. Invocaremos entonces al objeto con su método.\n","\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.set_montage <br><br>\n","  Objeto mne.io.Raw</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.set_montage\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>montage</td><td>El nombre del montaje que queremos aplicar: \"standard_1020\"</td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto tipo  \n","<a href=\"https://mne.tools/stable/generated/mne.io.Raw.html\"\n","    target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","  mne.io.raw</a>. Es el objeto EEG ya con montaje aplicado.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TsLQt6ejYkO"},"outputs":[],"source":["#Recuperamos el objeto que contiene el montaje de la librería MNE.\n","montage = mne.channels.make_standard_montage(\"standard_1020\")\n","# Lo aplicamos mediante un for loop a cada objeto EEG.\n","\n","for sub, eeg in original_eeg.items():\n","  eeg=eeg.copy() #para no cambiar el objeto mismo mientras iteramos en él.\n","  eeg.set_montage(montage) #aplicamos el montaje.\n","  original_eeg[sub]=eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64FVy43dOI69"},"outputs":[],"source":["display(original_eeg['01'])"]},{"cell_type":"markdown","metadata":{"id":"MUYm260tiPbO"},"source":["Mediante el método `plot_sensors`, podemos tener una idea de cómo se ubican los electrodos en este montaje. Intenemos plotearlo en 2D y 3D, porque...  \n","\n","¿Por qué no?\n","\n","<br>\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.plot_sensors <br><br>\n","  Objeto mne.io.Raw</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.plot_sensors\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>kind</td><td>Utilizaremos \"topomap\" para la visión 2D y luego \"3d\" en la segunda aplicación. </td></tr>\n","<tr><td>show_names</td><td>True o False. Para mostrar o no el nombre de los electrodos. </td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Figura de montaje creada con matplotlib.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P68DY6GIiOr0"},"outputs":[],"source":["graph1=original_eeg['01'].plot_sensors(kind='topomap', show_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JzsvskLEOI7D"},"outputs":[],"source":["graph2=original_eeg['01'].plot_sensors(kind='3d', show_names=True)"]},{"cell_type":"markdown","metadata":{"id":"e0bB2uzh8GAy"},"source":["Y lo último, pero ni de lejos menos importante, son los métodos para poder ver la señal en el tiempo.\n","\n","<br>\n","\n","Si ejecutamos MNE-Python en un entorno de desarrollo en nuestras máquinas, tendremos acceso a gráficos interactivos (por los cuales se puede navegar en la señal, como en un video). Sin embargo, en Google Colab, esa opción no está disponible. Igual, podríamos arreglárnoslas para ver la señal en el tiempo, porque al fin y al cabo estamos en Python; pero la verdadera limitante es la capacidad de procesamiento de Google Colab.\n","\n","<br>\n","\n","Probemos utilizando el método <code>.plot()</code> del objeto EEG/'raw'. Sin argumentos, ni nada.  \n","\n","<br>\n","\n","Accedamos al objeto llamando al diccionario e indicando la clave (id del participante) asociada, para aplicar el método en cuestión.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eugoP4VutPg"},"outputs":[],"source":["graph1=original_eeg['01'].plot()"]},{"cell_type":"markdown","metadata":{"id":"AdQ0J6mjmouJ"},"source":["# Filtrado y limpieza de artefactos."]},{"cell_type":"markdown","metadata":{"id":"RCakzN4Duai2"},"source":["El siguiente paso es el filtrado y la limpieza de artefactos.\n","\n","En realidad, denominarlo como sólo un único paso es subestimar todo lo que es posible hacer para mejorar la señal y librarse de los artefactos o ruido. Recordemos que, si bien estamos midiendo actividad cerebral a nivel del cuero cabelludo, la fuente primaria de voltaje y ritmos todavía se encuentra tras muchas capas.  \n","\n","Cada una de estas capas, más los factores asociados al experimento, pueden hacer que nos preguntemos:\n","\n","<br>\n","\n","\n","---\n","<br>\n","\n","<center>\n","\n","Este voltaje/ritmo... ¿Es producto de la actividad cerebral? ¿O producto de la interacción de algo más con esta?\n","\n","</center>\n","\n","<br>\n","\n","\n","---\n","\n","<br>\n","\n","Para responder a esas preguntas, lo ideal es adentrarnos a preguntarnos ¿Qué entendemos por actividad cerebral? ¿Qué es un \"ritmo\"? o ¿\"Voltaje\"?  "]},{"cell_type":"markdown","metadata":{"id":"s-Yna6oxGiMO"},"source":["## Entendiendo los ritmos del cerebro.\n","\n","Uno de los conceptos más usados hoy en día es el de \"frecuencias cerebrales\" o \"ritmos cerebrales\". Se utiliza para hablar acerca de la forma de las ondas que están asociadas a cierta actividad cerebral. A grandes rasgos, las más conocidas son las siguientes:\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/02.png\"\n","       alt=\"montaje\"\n","       style=\"display:block; margin:0 auto; max-width:100%; width:1080px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Frecuencias de actividad cerebral.</figcaption>\n","</figure>\n","\n","<br>\n","\n","Pero ¿Qué es un ritmo? ¿Qué es una frecuencia? Para dar con el concepto clave, podemos aproximarnos de la manera más ingenua: Una frecuencia es cuán frecuente es algo, cuánto sucede en el tiempo.\n","\n","Si algo sucede a una frecuencia de 1Hz, es lo mismo que decir que sucede cada segundo. Si sucede 10Hz, sucede 10 veces por segundo (0.1 ms), y así sucesivamente.\n","\n","**¿Pero qué es lo que sucede?**  \n","\n","En este caso, de cuántas oscilaciones suceden en el tiempo.  \n","\n","En el ejemplo hipotético, todas las oscilaciones son matemáticamente perfectas, pero en los EEG no **¿Entonces? ¿Cómo hacemos?**\n","\n","<br>\n","\n","Por suerte, no somos los primeros que se hacen esa pregunta. En realidad, muchas veces lo que se hace es un intento matemático de estimar una señal compleja en sus señales más simples. Tanto para medirla, construirla o deconstruirla.\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/01.png\"\n","       alt=\"montaje\"\n","       style=\"display:block; margin:0 auto; max-width:80%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Frecuencias juntas.</figcaption>\n","</figure>\n","\n","\n","<br>\n","\n","Todas estas tretas matemáticas han servido para darnos cuenta de que el cerebro tiene frecuencias específicas durante ciertos estados, ya sea actividad, sueño, estrés, percepción de ambigüedad, etc.\n","\n","<br>\n","\n","Ojo, frecuencias en la medición de EEG cortical, porque la realidad es más compleja.\n","\n","<br>\n","\n","\n","\n","<center>\n","\n","\n","\n","> ¿Puede el cerebro tener latidos distintos al mismo tiempo?\n","\n","\n","\n","</center>\n","\n","<br>\n","\n","<br>\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/03.png\"\n","       alt=\"montaje\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Diferencia de frecuencias entre pliegues.       <a href=\"https://www.nature.com/articles/s41593-023-01554-7\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      Fuente.\n","  </a></figcaption>\n","</figure>\n","\n","<br>\n","\n","<br>\n","\n","<br>\n","\n","<br>\n","\n","<br>\n","\n","<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"nMnfVKeuE2pj"},"outputs":[],"source":["#@title Black Box_(Ｙｏｕ have encountered ａｎｏｔｈｅｒ BlackBox. What would you do?)\n","# Bandas EEG y sus rangos\n","eeg_bands = {\n","    \"Delta\": (0.5, 4),\n","    \"Theta\": (4, 8),\n","    \"Alfa\": (8, 13),\n","    \"Beta\": (13, 30),\n","    \"Gamma\": (30, 100)\n","}\n","\n","eeg_colors = {\n","    \"Delta\": \"#00ffd5\",\n","    \"Theta\": \"#ff00ff\",\n","    \"Alfa\": \"#b6ff00\",\n","    \"Beta\": \"#ff6ec7\",\n","    \"Gamma\": \"#00ffff\"\n","}\n","\n","def get_band_and_color(freq):\n","    for name, (low, high) in eeg_bands.items():\n","        if low <= freq < high:\n","            return name, eeg_colors[name]\n","    return \"Fuera de rango\", \"#ffffff\"\n","\n","def plot_senoide(freq, dur):\n","    fs = 1000\n","    t = np.arange(0, dur, 1/fs)\n","    y = np.sin(2 * np.pi * freq * t)\n","\n","    band_name, color = get_band_and_color(freq)\n","\n","    fig, ax = plt.subplots(figsize=(8, 3), dpi=150)\n","    fig.patch.set_facecolor(\"#0a0f1f\")\n","    ax.set_facecolor(\"#0a0f1f\")\n","\n","    ax.plot(t, y, linewidth=8, alpha=0.08, color=color)\n","    ax.plot(t, y, linewidth=2.2, color=color)\n","\n","    ax.set_xlim(0, dur)\n","    ax.set_ylim(-1.2, 1.2)\n","    ax.set_xlabel(\"Tiempo (s)\", color=\"#cde3ff\")\n","    ax.set_ylabel(\"Amplitud\", color=\"#cde3ff\")\n","    ax.set_title(\n","        f\"Frecuencia: {freq:.2f} Hz  →  Banda: {band_name}\",\n","        color=\"#e6f0ff\",\n","        pad=10\n","    )\n","\n","    for spine in ax.spines.values():\n","        spine.set_color(\"#20345c\")\n","        spine.set_linewidth(1.2)\n","\n","    ax.tick_params(colors=\"#a8c8ff\")\n","    ax.grid(True, which=\"both\", linewidth=0.6, alpha=0.25)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Sliders\n","freq_slider = ipywidgets.FloatSlider(\n","    value=10.0, min=0.5, max=50.0, step=0.5,\n","    description='Frecuencia (Hz):'\n",")\n","\n","dur_slider = ipywidgets.FloatSlider(\n","    value=1.6, min=0.1, max=1.0, step=0.1,\n","    description='Duración (s):'\n",")\n","\n","ipywidgets.interactive(\n","    plot_senoide,\n","    freq=freq_slider,\n","    dur=dur_slider\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"Fse4x7NrMxAl"},"source":["## Frecuencias que no pertenecen al cerebro.\n","\n","<br>\n","\n","El EEG capta muchas frecuencias, entre ellas la de la alimentación de corriente eléctrica (50hz / 60hz dependiendo del país), la de contaminación de aparatos eléctricos cercanos, etc.\n","\n","<br>\n","\n","Incluso, frecuencias que no pertenecen a la actividad cerebral pueden ser transmitidas mediante el participante también, puesto que los movimientos musculares o de la mandibula influyen en la señal captada.\n","\n","<br>\n","\n","Para esto, existen convenciones de filtrado en los estudios de EEG. Normalmente se filtran afuera las frecuencias específicas de la electricidad (mediante un filtro llamado notch) y luego se hace un filtrado de un rango de frecuencias específicas. Esto se llama ``bandpass filter``. Es básicamente decir \"quiero que midas las frecuencias desde este valor hasta este otro valor\".  \n","\n","<br>\n","\n","En este caso, el intervalo de esos valores idealmente son las frecuencias que nos interesan: las que pertenecen al cerebro o a la actividad que se estudia.  \n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"m3n6xzD6PDVT"},"source":["## Las referencias. Unidades de medición.\n","\n","¿Existe una unidad de medición absoluta?\n","\n","<br>\n","\n","Toda medición se suele hacer siempre respecto a una referencia. Si digo \"2 segundos\", \"1 día\", \"2 kilómetros\", siempre estoy asumiendo un punto de comparación (desde que cuento, desde que el lugar que empiezo a medir). Medir suele ser análogo a comparar.  \n","\n","<br>\n","\n","En el caso del EEG, el voltaje se mide con electrodos de referencia. Podemos pensar en la idea del voltímetro.\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://cdn.pixabay.com/photo/2014/11/09/02/53/multimeter-523153_1280.jpg\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Voltímetro.</figcaption>\n","</figure>\n","\n","\n","Los electrodos sobre los que se suelen medir son los mastoides, pero mientras procesamos los datos podemos cambiar de referencia. Recordemos que sólo es un punto de comparación. En este caso, el punto de comparación del estudio de Isasi-Isasmendi, et al. (2024) fue el promedio de los mastoides (el promedio del valor de dos electrodos como referencia).  \n","\n","<br>\n","\n","En estudios de eeg, una referencia común también es el \"average reference\", que es tomar el promedio de todos los electrodos como punto de referencia.  \n","\n","<br>\n","\n","En este caso, comenzaremos con un filtro bandpass y luego con la asignación de la referencia al promedio de los mastoides. Los métodos que utilizaremos los tiene el objeto EEG/'Raw': <code> .filter</code> y <code> .set_eeg_reference</code>.\n","\n","\n","\n","\n","<br>\n","\n","\n","<br>\n","\n","\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.filter\n","  <br><br>\n","  Objeto mne.io.Raw\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.filter\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>l_freq</td><td>Frecuencia que estará en el límite inferior. Sólo pasarán las frecuencias más altas que esta. En nuestro caso: 0.1. </td></tr>\n","<tr><td>h_freq</td><td>Frecuencia que estará en el límite superior. Sólo pasarán las frecuencias más bajas que esta. En nuestro caso: 40. </td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","El mismo objeto con el paso de banda aplicado. Sólo pasan las frecuencias entre 0.1 y 40 Hz.\n","</table>\n","\n","\n","\n","<br>\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.set_eeg_reference <br><br> Objeto mne.io.Raw</strong>\n","  \n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.filter\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>ref_channels</td><td>Canal que será la nueva referencia. Si es una lista, se promedian los canales. Si es 'average', se referencia al promedio de todos los electrodos. </td></tr>\n","\n","<td colspan=\"2\">\n","El mismo objeto con la referencia aplicada.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohRTCcz8jm2D"},"outputs":[],"source":["#No estamos aplicando un notch_filter porque el filtro de paso de banda ya deja fuera la corriente.\n","filtered_eeg={}\n","for sub, eeg in original_eeg.items():\n","  eeg=eeg.copy()\n","  eeg=eeg.filter(l_freq=0.1, h_freq=40)\n","  eeg=eeg.set_eeg_reference(ref_channels=['TP9', 'TP10'])\n","  filtered_eeg[sub]=eeg"]},{"cell_type":"markdown","metadata":{"id":"27X7G6Lg3T1b"},"source":["## Remover electrodos con señal dañada\n","\n","<br>\n","\n","Otra práctica común es remover electrodos que no están funcionando bien. En el paper que intentamos replicar, utilizaron un criterio concreto: los electrodos con señal que superaba 5 desviaciones estándar de la media de todos los electrodos eran removidos.  \n","\n","<br>\n","\n","Aquí intentaremos replicar lo que hicieron con una librería que se integró a MNE: **PyPrep**.  \n","\n","<br>\n","\n","\n","---\n","\n","<br>\n","\n","> <left>\n","PyPrep es un paquete que se encarga de implementar el pipeline PREP para descartar electrodos dañados.\n","\n","</left>\n","\n","<br>\n","\n","---\n","\n","<br>\n","\n","Dentro de Pyprep tenemos varias técnicas para descartar electrodos:\n","\n","*   Correlación con los demás\n","*   Comparación con la Desviación Estándar de la media de electrodos.\n","*   RANSAC (Random Sample Consensus)\n","*   SNR (Signal to Noise Ratio)\n","*   High frequency noise o Ruido de alta frecuencia.\n","*   Señales vacías.\n","\n",", etc. En esta ocasión, utilizaremos el método ```.find_bads_by_deviation```, que nos permite detectar electrodos dañados en base a la desviación estándar.\n","\n","<br>\n","\n","Para ello, tendremos que construir un objeto PyPrep con ciertas características que que queremos que se apliquen en el pipeline. Este objeto se creará mediante la función <code> pyprep.NoisyChannels </code>. El método ```.find_bads_by_deviation``` se aplica al nuevo objeto.\n","\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>pyprep.NoisyChannels</strong>\n","  \n","  </strong>\n","      <a href=\"https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>raw</td><td>Archivo EEG/'Raw' de MNE. PyPrep sólo se puede aplicar a este nivel. </td></tr>\n","<tr><td>do_detrend</td><td>True or False. PyPrep puede filtrar la señal por nosotros, poniéndole un límite inferior de 1. En este caso, nuestra señal ya está filtrada, así que será False. </td></tr>\n","<tr><td>random_state</td><td>Métodos internos de PyPrep usan la simulación aleatoria para comparar si los valores se deben al azar. Aquí escogemos un \"seed\" o dimensión en la que queremos que se ejecute lo aleatorio (7). </td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto PyPrep con métodos que pueden aplicarle técnicas de rechazo de electrodos.\n","</table>\n","\n","<br>\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.find_bad_by_deviation</strong>\n","<br><br> Objeto pyprep.NoisyChannels</strong>\n","  </strong>\n","      <a href=\"https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html#pyprep.NoisyChannels.find_bad_by_deviation\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","<tr><td>deviation_threshold</td><td>Umbral (en valores normalizados o Z-scores) para ejecutar el rechazo. Utilizaremos el valor 5.0 para rechazar si se aleja más de 5 DE de la media. </td></tr>\n","\n","</table>\n","\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7M2tJQHOkFon"},"outputs":[],"source":["#Luego está la selección a nivel de electrodos:\n","for sub, eeg in filtered_eeg.items():\n","  noisy=pyprep.NoisyChannels(raw = eeg,\n","                            do_detrend=False, #Importante para que la herramienta no aplique un filtro por nosotros.\n","                            random_state=7)\n","  noisy.find_bad_by_deviation(deviation_threshold=5.0) #Esto es lo que se aplicó en el paper.\n","  eeg.info['bads'] = noisy.get_bads()\n","  results=noisy.get_bads(as_dict=True)\n","  print(f\"Se encontró {len(eeg.info['bads'])} canales ruidosos\")"]},{"cell_type":"markdown","metadata":{"id":"MU0OyoSISmXp"},"source":["Si se dieron cuenta, utilizamos al final el método `.get_bads`, para poder recuperar la información de los canales rechazados.  \n","\n","Esta información la estamos copiando en el atributo `.info` del objeto original, que guarda datos relacionados a la señal.\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.get_bads</strong>\n","<br><br> Objeto pyprep.NoisyChannels</strong>\n","  </strong>\n","      <a href=\"https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html#pyprep.NoisyChannels.get_bads\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","\n","\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Diccionario con los electrodos rechazados.\n","</table>\n","\n","</table>\n","\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Atributo: <strong>.info</strong>\n","<br><br> Objeto mne.io.Raw</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","<br>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos a los que accede:</th></tr>\n","\n","<td colspan=\"2\">\n","Un diccionario con la metadata (o simplemente data sobre el EEG). Utilizamos la key 'bads' para agregar información de los electrodos dañados.\n","</table>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","collapsed":true,"id":"V6LuXqSVd7nD"},"outputs":[],"source":["#@title Black Box (Inspeccionar Electrodos)\n","def plot_sensors(sub):\n","    object = filtered_eeg[sub]\n","    object.plot_sensors(\n","        kind='topomap',\n","        show=True,\n","        show_names=True\n","    )\n","\n","toggle_sub=ipywidgets.ToggleButtons(\n","    options=['23', '05', '04', '02', '01'],\n","    description='Sub Key:',\n","    disabled=False,\n","    button_style='',\n","    style={'button_width':'5em'},\n",")\n","label = ipywidgets.HTML(\n","    value=\"<div style='font-size:18px; text-align:left;'>¿Qué sujeto tiene electrodos rechazados?</div>\"\n",")\n","\n","sensor_widget = ipywidgets.interactive(\n","    plot_sensors,\n","    sub=toggle_sub\n",")\n","\n","ipywidgets.VBox([label, sensor_widget])\n"]},{"cell_type":"markdown","source":["\n","De momento, podemos recapitular los pasos de pre procesado que hemos hecho hasta ahora.\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_02.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Estado del tutorial.</figcaption>\n","</figure>\n"],"metadata":{"id":"lEU88k5Fb8Cv"}},{"cell_type":"markdown","metadata":{"id":"ALPN6e3OTTJf"},"source":["# Independent Component Analysis (ICA)"]},{"cell_type":"markdown","metadata":{"id":"9xHNbj_QTzGj"},"source":["Algunos dirían que es el peso pesado, otros que no siempre es necesario. Querido, odiado y muchas veces incomprendido. La realidad es que el ICA es una de las herramientas más usadas en el pre-procesamiento de EEG.\n","\n","<br>\n","\n","Usa el principio matemático de detectar comportamientos singulares en la señal, que parecen presentarse de manera invariable e independiente de la tendencia general.\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/4._Fish_at_Sea_Surface_of_Karimunjawa.jpg\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Banco de peces en el mar de Karimunjawa.</figcaption>\n","</figure>\n","\n","<br>\n","\n","Si estuviéramos en el océano y viésemos, además de las olas, ondas particulares, podríamos deducir que hay algo distinto bajo el agua. El ICA usa principios similares para detectar componentes que no pertenecen al patrón inherente de la señal; detecta fuentes \"independientes\" de ondas. Independientes, en este caso, al resto de la señal.\n","\n","<br>\n","\n","Luego de tretas matemáticas complejas, el ICA nos da un mapa con componentes independientes y nos permite seleccionar los elementos que no queremos.\n","\n","<br>\n","\n","-----\n","\n","<br>\n","\n","\n","<center>\n","\n","El objetivo es borrar los componentes que sabemos que no pertenecen a la señal cerebral.\n","\n","</center>\n","\n","<br>\n","\n","\n","-----\n","\n","\n","\n","<br>\n","<br>\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/04_ai.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Analogía de componentes.</figcaption>\n","</figure>\n","\n","\n","\n","\n","<br>\n","\n","Al retirar los elementos innecesarios, aplica el mapa resultante sobre los datos para reconstruirlos. Esto se conoce como \"limpiar los datos\".\n","\n","<br>\n","\n","<h2>Recomendaciones generales para el ICA</h2>\n","\n","<br>\n","\n","El consenso general es que el ICA suele ser sensible al ruido de baja frecuencia. Debido a ello, es \"entrenado\" con la señal original, pero filtrada con un high-pass de 1.0 Hz (es decir, eliminando las ondulaciones más lentas). Como es una solución geométrica/estadística, el mapa resultante del entrenamiento puede ser aplicado a la señal original o con otro filtrado. Pero hay que tener consideraciones importantes:\n","\n","<br>\n","\n","*   La señal de entrenamiento y la de recepción deben tener la misma dimensionalidad (mismo número de electrodos, por ejemplo).\n","*   Se recomienda que para, ver los efectos reales, la señal de entrenamiento tenga la misma referencia de la señal de recepción.\n","*   El ICA se considera una transformación **lineal**. Esto quiere decir que es reversible. Una señal transformada con un mapa puede ser destransformada con la información del mismo mapa. Sin embargo, si realizamos un cambio entre esas transformaciones, no será posible recuperar la señal.\n","\n","<br>\n","\n","<h2>Creando datos de entrenamiento para el ICA</h2>\n","\n","<br>\n","\n","Preparémonos para aplicar el ICA. Primero, necesitamos una señal filtrada para no dejar pasar las frecuencias lentas. Se recomienda un filtro `l_freq=1.0, h_freq=None`, pero esta vez utilizaremos 1.0 - 100. No se preocupen, luego esto tendrá bastante sentido.\n","\n","<br>\n","\n","<center>\n","\n","> Nuestra señal ya fue filtrada de 0.1 a 40 Hz. Ya no podemos recuperar las frecuencias mayores a 40Hz. Debido a ello, tendremos que acudir a nuestra señal original sin filtrar para hacer una copia.\n","\n","</center>\n","\n","<br>\n","\n","Como en la nueva señal nos quedaremos con las frecuencias entre 40Hz y 100Hz, tendremos que aplicar un filtro para librarnos de la frecuencia de la corriente del artefacto. Estos filtros específicos se llaman notch, y podemos hacerlo con el método `.notch_filter`.\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.notch_filter</strong>\n","<br><br> Objeto mne.io.Raw</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.notch_filter\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","<tr><td>freqs</td><td>Frecuencia o frecuencias que queremos filtrar. Si ponemos una lista, tendrá que ser entre paréntesis. Utilizaremos (50,60) para filtrar 50Hz y 60Hz. </td></tr>\n","\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto EEG filtrado.\n","</table>\n","\n","</table>\n","\n","\n","<br>\n","\n","\n","Luego del filtro notch, recuperaremos los electrodos dañados copiando la información de ```.info['bads']``` de la señal original de cada participante, pues a esta ya aplicamos el criterio de rechazo de 5 desviaciones estándar.\n","\n","<br>\n","\n","El siguiente paso sería re-referenciar la señal también con ```.set_eeg_reference```. Guardaremos los datos para entrenar el ICA en el diccionario ```train_eeg```\n","\n","\n","En general, queremos seguir el siguiente flujo:\n","\n","\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_03.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Flujo con copia de entrenamiento.</figcaption>\n","</figure>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pfJJmfQjES5"},"outputs":[],"source":["############################################\n","#########Preparing training data############\n","############################################\n","#Creamos un diccionario para guardar las copias de entrenamiento\n","train_eeg={}\n","\n","#Empezamos iterando en el diccionario de los datos originales.\n","for sub, eeg in original_eeg.items(): #devuelve pares key:value. Ej: '23', ObjectoEEG.\n","  train_copy=eeg.copy()\n","  train_copy=train_copy.filter(l_freq=1.0,\n","                              h_freq=100 #¡¿Cómo?!\n","                              )\n","  train_copy.notch_filter( #Nuestro filtro notch\n","      freqs=(50, 60)\n","      )\n","  train_copy.info['bads'] = filtered_eeg[sub].info['bads'] #copiamos la información sobre los canales que se encontraron dañados (las marcas \"bad channel\")\n","  train_copy=train_copy.set_eeg_reference('average')\n","  #Guardamos en el diccionario. La key es la variable 'sub' en la iteración, la cual guarda el id del sujeto.\n","  train_eeg[sub]= train_copy"]},{"cell_type":"markdown","metadata":{"id":"ho-jGHkjjVCH"},"source":["Y aquí ya estaríamos listos para el ICA. Sin embargo, un dato clave para el ICA es la dimensionalidad de nuestra data.\n","\n","<br>\n","\n","<center> <em>\n","\n","> ¡¿Y cómo se hace eso profe?! Ya me mareé ¡¿Y ahora tengo que hacer matemáticas?!\n","</em>  \n","(ノಠ益ಠ)ノ彡┻━┻ </center>\n","\n","<br>\n","\n","¡Tranquilos! Por suerte, estamos en Python, así que el trabajo duro lo hará una función (*¿o el trabajo duro era pensar para qué usar las funciones?...*).\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne.compute_rank</strong></strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.compute_rank.html#mne.compute_rank\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","<tr><td>inst</td><td>Archivo EEG del cual queremos que compute la dimensionalidad. </td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Diccionario que contiene: tipo de canal(key) y rango (value). En nuestro caso, sólo tendremos 'eeg': rank. Con los parámetros por defecto, el rango es un indicador de la dimensionalidad.\n","</table>\n","\n","\n","<br>\n","\n","\n","El rango es un simple número entero (como 32, 30, 28). Este número será un parámetro de nuestro ICA.\n","\n","<h2>Creando el ICA</h2>\n","\n","¡Ahora sí! Ya podemos aplicar el ICA. Para ello, crearemos un nuevo objeto (casi como lo hicimos en PyPrep), el cual contendrá los parámetros de nuestro análisis.\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne.preprocessing.ICA</strong></strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","<tr><td>n_components</td><td>El número de componentes que queremos que estime. Aquí es donde va el número del rank. </td></tr>\n","<tr><td>method</td><td>Método para realizar la computación. Elegiremos 'infomax'. </td></tr>\n","<tr><td>fit_params</td><td>Diccionario que indica los parámetros adicionales del método. {'extended':True} para infomax extendido. </td></tr>\n","<tr><td>max_iter</td><td>Controla el número de iteraciones para el cálculo. 'auto' para que la función decida por sí sola. </td></tr>\n","<tr><td>random_state</td><td>Seed para replicabilidad. Universo 7. </td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objecto ICA con los parámetros que definimos. Listo para entrenarse con una señal.\n","</table>\n","\n","\n","<br>\n","\n","El objeto que obtenemos aún no está entrenado. Para hacer esto, usamos el método <code>.fit</code> para seleccionar la señal con la que se entrenará.\n","\n","<br>\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.fit</strong></strong>\n","  </strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.fit\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","\n","<tr><td>inst</td><td>La data eeg que se quiere para entrenar el ICA y dibujar los \"mapas\". </td></tr>\n","<tr><td>picks</td><td>Tipo de canales que se quieren considerar para construir los mapas ICA. Por default canales que tienen señal cerebral ('eeg' o 'meg' por ejemplo). Es buena práctica siempre delimitarlo de forma explícita ('eeg' en nuestro caso). </td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objecto ICA con el mapa de transformación y destransformación.\n","\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5ORE8Cg7VLO"},"outputs":[],"source":["\n","\n","\"\"\"\n","NO EJECUTAR ESTE CÓDIGO.\n","\n","Ejecutar este código podrá romper el entorno Colab, porque no tiene suficiente\n","capacidad para procesar el ICA en un tiempo aceptable.\n","\n","Para ejecutarlo, si se quiere rehusar, es necesario quitarle las comillas\n","con las que empieza y termina\n","\n","########################\n","#########ICA############\n","########################\n","#Creemos un diccionario para guardar soluciones ica\n","ica_objects={}\n","for sub, eeg in train_eeg.items(): #Iteramos en los datos de entrenamiento.\n","  rank_train_dictionary=mne.compute_rank(eeg)\n","  rank_train=rank_train_dictionary['eeg']\n","\n","  ica = mne.preprocessing.ICA(\n","              n_components=rank_train, #Rank o dimensiones independientes.\n","              method = \"infomax\",  # Método a elegir.\n","              fit_params = {'extended':True}, #Parámetros del método, hay \"infomax\" e \"infomax extended\". Queremos el extended.\n","              max_iter = \"auto\",  # Maximum number of iterations; typically should be higher, like 500 or 1000\n","              random_state = 7  # Lucky!\n","          )\n","\n","  ica.fit(eeg, picks='eeg') #eeg es por default, pero es buena práctica.\n","\n","  ica_objects[sub]=ica\n","\n","\n","  \"\"\""]},{"cell_type":"markdown","metadata":{"id":"Ryo0RdGyodOL"},"source":["# Practicar ICA"]},{"cell_type":"markdown","metadata":{"id":"vvQBXYtBdUM3"},"source":["<h2>Recuperación de soluciones ICA</h2>\n","\n","<p>\n","Google Colab puede demorar al aplicar ICA. Sin embargo, como al final el ICA produce\n","<i>mapas</i> (matrices de mezcla y desmezcla), podemos guardarlos y recuperarlos\n","como objetos independientes.\n","</p>\n","\n","\n","\n","<p>\n","En este caso, nuestra caja negra recuperará el <b>mapa del participante 23</b>\n","(como un objeto ICA), el cual fue preprocesado junto con todos los demás con el código anterior.\n","</p>\n","\n","\n","<details open>\n","    <summary><b>¿Por qué guardar los mapas?</b></summary>\n","    <ul>\n","      <li>Evitar recalcular ICA completo entre sesiones de análisis.</li>\n","      <li>Reproducibilidad: Documentar el resultado de seguir el mismo <i>pipeline</i> y usar los mismos objetos.</li>\n","      <li>Facilita análisis detenido por participante.</li>\n","    </ul>\n","</details>\n","\n","\n","<br>\n","\n","Al recuperar los mapas del ICA nos abremos saltado una parte del flujo, vamos a recapitular para no perdernos:\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_04.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Flujo al saltarnos la computación.</figcaption>\n","</figure>"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"GyyW44YHoVBa"},"outputs":[],"source":["#@title Black Box_(download solution objects)\n","%%capture\n","!wget \"https://drive.usercontent.google.com/download?id=1GJD2iwv9UOOCbHIYTpWTYXwykyB0_eYU&export=download&confirm\" -O withoutlabel.zip\n","!unzip -o withoutlabel.zip -d /content/\n","ica = mne.preprocessing.read_ica(\"./objects_unlabeled/23_ica.fif\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbauE-ly4Qyi"},"outputs":[],"source":["ica"]},{"cell_type":"markdown","metadata":{"id":"1-AkFik_Yn2P"},"source":["<h2>Participante 23</h2>\n","\n","\n","El objeto ICA del participante 23 intentó encontrar 28 componentes (se evaluó que nuestros datos tenían 28 dimensiones, así que ese era el número máximo lógico).  \n","\n","Intentemos aplicar el mapa a nuestros datos. Como ya ejecutamos el filtrado, accedemos al diccionario y hacemos una copia del objeto de entrenamiento con el que se dibujó el mapa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEqVrD1NKNOk"},"outputs":[],"source":["#Creemos una copia del objeto original del participante 23.\n","single_test_sub=train_eeg['23'].copy()"]},{"cell_type":"markdown","metadata":{"id":"pZJbqgmvrg9U"},"source":["<h2>Explorando soluciones ICA</h2>\n","\n","<br>\n","\n","Lo primero que podemos hacer es aplicar el método `.plot_components()`, así sin nada más, ni un argumento. <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.plot_components\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [documentación del método]\n","  </a>\n","\n","\n","<br>\n","\n","\n","Esto nos dará las topografías de los componentes en donde observaremos la actividad de cada componente en los electrodos.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmxPETPRrdit"},"outputs":[],"source":["graph=ica.plot_components()"]},{"cell_type":"markdown","metadata":{"id":"EriaW1JBssF1"},"source":["Si ejecutamos MNE en nuestras computadoras, estos gráficos serán interactivos. Es decir, nos abrirán ventanas con los detalles de cada componente. Sin embargo, también hay formas para obtener esa información si no disponemos de una interfaz interactiva. Utilizaremos los métodos .`plot_properties ` y `.plot_sources`.\n","\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.plot_properties</strong></strong>\n","  </strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.plot_properties\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","<br>\n","<tr><td>inst</td><td>La data eeg para estimar señales de componentes. Aquí irá \"single_test_sub\", pues es la copia de la data con la que entrenamos. </td></tr>\n","<tr><td>picks</td><td>Índices de los componentes o lista de índices de los componentes. Iremos por el 3. </td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Figura con detalles de la señal del componente.\n","</table>\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.plot_sources</strong></strong>\n","  </strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.plot_sources\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","<br>\n","<tr><td>inst</td><td>La data eeg para estimar señales de componentes. Aquí irá \"single_test_sub\", pues es la data con la que entrenamos. </td></tr>\n","<tr><td>picks</td><td>Índices de los componentes o lista de índices de los componentes. Iremos por el 3 para complementar las properties. </td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Figura con la señal de cada componente. Por default, se muestra también la señales de los electrooculogramas del aparato (HEOG, VEOG) para ayudar a examinar si los componentes pertenecen a señales oculares.\n","</table>\n","\n","<br>\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAgnw2fMueOH"},"outputs":[],"source":["graph1=ica.plot_properties(inst=single_test_sub, picks=[3])\n","graph2=ica.plot_sources(inst=single_test_sub, picks=[3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnofkRn2Sw2g","cellView":"form"},"outputs":[],"source":["#@title Black Box (Explorar componentes)\n","def ica_plot_properties(picks):\n","    ica.plot_properties(inst=single_test_sub,\n","             picks=picks,\n","             show=True)\n","toggle=ipywidgets.ToggleButtons(\n","    options=[0, 1, 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],\n","    description='Componente:',\n","    disabled=False,\n","    button_style='',\n","    style={'button_width':'12em'}\n",")\n","\n","component_widget = ipywidgets.interactive(\n","    ica_plot_properties,\n","    picks=toggle\n",")\n","\n","display(component_widget)"]},{"cell_type":"markdown","metadata":{"id":"-zESVRUgwblK"},"source":["Recordemos la finalidad del ICA: Seleccionar componentes que no pertenecen a actividad cerebral. Si queremos marcar componentes, podemos agregar el índice del componente al atributo `.exclude`, el cual almacena una lista de componentes para excluir. <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.fit\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [documentación en la parte de \"atributos\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ABxZpWRtDa74"},"outputs":[],"source":["#Veremos que nuestra lista está limpia\n","ica.exclude\n","\n","#Si quisiéramos agregar, podríamos hacer lo siguiente\n","#ica.exclude=1\n","#ica.exclude=[0,4]"]},{"cell_type":"markdown","source":["Recapitulación secuencial:\n","\n","´training eeg´"],"metadata":{"id":"FJBKxh3Xcy8z"}},{"cell_type":"markdown","metadata":{"id":"BdCUNz-yEWyN"},"source":["<h2>Técnicas para detectar componentes de artefactos: <code>find_bads_eog</code> e ICALabel</h2>\n","\n","Dos de las técnicas más accesibles y a la vez eficientes que tiene MNE para detectar componentes que pertenecen a artefactos, son el método <code>find_bads_eog</code> y la librería complementaria <span style=\"text-transform:uppercase; font-size:0.9em; letter-spacing:0.5px;\">\n","ICALabel.\n","</span>\n","\n","<br>\n","\n","\n","\n","<h2><code>find_bads_eog</code></h2>\n","\n","\n","<br>\n","\n","<code>find_bads_eog</code> se encarga de descartar componentes encontrados por el ICA en base a la correlación que tiene con la señal de los electrooculograma (EOG).  \n","\n","<br>\n","\n","En teoría, si nuestro componente tiene una fuerte correlación con lo que sucede en el EOG, que se encarga de medir los cambios de potencial alrededor de los ojos, entonces no pertenecería a actividad cerebral.  \n","\n","<br>\n","\n","Podemos configurar el umbral que la función utiliza para decidir si el componente se parece o no a la señal del EOG, en este caso, utilizaremos el valor por defecto <code>0.3</code>. De igual forma, mediante el parámetro <code>ch_name</code> le decimos al método contra qué canales queremos que se haga la comparación. En este estudio, se tuvieron dos EOG dedicados: <code>HEOG</code> y <code>VEOG</code>.\n","\n","<br>\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.find_bads_eog</strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.find_bads_eog\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","  \n","  </th></tr>\n","  <tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","  <tr><td>inst(objeto con señal)</td><td>La señal sobre la cual queremos que se compute el método.</td></tr>\n","  <tr><td>ch_name</td><td>El nombre de los canales para utilizar como \"EOG\" en el cálculo. En este caso \"VEOG\" y \"HEOG\".</td></tr>\n","  <tr><td>threshold</td><td>Umbral por sobre el cual el componente es clasificado como valor extremo o no (outlier, anómalo). </td></tr>\n","  <tr><td>verbose</td><td>Controla si queremos datos del estado del proceso. Por default True, pero para outputs más legibles lo setearemos en False. </td></tr>\n","  <tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","  <td colspan=\"2\">\n","  Dos diccionarios, uno con el índice de los objetos detectados como pertenecientes a artefactos, y otro con el índice de correlación de todos los componentes.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crsGuRnjsbBs"},"outputs":[],"source":["#ya tenemos el objeto ica\n","ica #esto ya existe\n","#find_bads_eog\n","eog_indices, eog_scores = ica.find_bads_eog( #Este es el método.\n","    single_test_sub, #pasamos nuestro set de entrenamiento\n","    ch_name=['HEOG', 'VEOG'],\n","    threshold=3.0,\n","    verbose=False\n",")\n","\n","print(eog_indices)\n","print(\"Estos componentes han sido detectados, pero aún faltan ser agregados al atributo .exclude\")"]},{"cell_type":"markdown","metadata":{"id":"4-JGXVpGvKXm"},"source":["<h2>ICALabel</h2>\n","<br>\n","\n","El segundo instrumento que veremos para detectar componentes con artefactos será el de una librería diseñada para \"etiquetarlos\": icalabel\n","\n","<br>\n","\n","Esta librería es una de las tantas disponibles en software privado, como EEGLab, para automáticamente detectar componentes artefactuales. Se basa en la lógica de etiquetar a cada componente como: <code>'brain', 'muscle artifact', 'eye blink', 'heart beat', 'line noise', 'channel noise' or 'other'</code>.  \n","\n","<br>\n","\n","\n","Luego de asignar una etiqueta, también asigna una probabilidad de la certeza de dicha etiqueta, indicándola con un número entre 0 y 1. ICALabel fue originalmente entrenado en data de EEG que cumplía con las siguientes características:\n","\n","<br>\n","\n","<details open>\n","    <summary><b>Características de los objetos ICA con los que fue entrenado originalmente ICALabel:</b></summary>\n","    <ul>\n","      <li>Fueron computados a partir de señales filtradas entre 1.0 y 100 Hz.</li>\n","      <li>Las señales también se encontraban referenciadas al \"common average\".</li>\n","      <li>Los objetos (mapas) ICA obtenidos fueron producto del método \"extended infomax\".\n","    </ul>\n","</details>\n","\n","<br>\n","\n","Ya podemos entender un poco mejor por qué escogimos en nuestro flujo esos parámetros. Sin embargo, a pesar de que ICALabel recomienda que los datos tengan esas características, sí puede ser aplicado en soluciones ICA de datos con filtrados y referencias distintas. No obstante, se advierte que el desempeño del algoritmo puede variar.\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Función: <strong>mne_icalabel.label_components\n","  </strong>\n","      <a href=\"https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.label_components.html#mne_icalabel.label_components\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","    </a>\n","  </th>\n","  </tr>\n","\n","  <tr><th colspan=\"1\">Parámetros</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","  <tr><td>inst(objeto con señal)</td><td>La señal sobre la cual queremos que se proyecte el mapa ica en la función.</td></tr>\n","  <tr><td>ica (objeto ica)</td><td>La solución ica (mapa) que queremos utilizar para etiquetar.</td></tr>\n","  <tr><td>method</td><td>Método para etiquetar. Puede ser \"icalabel\" o \"megnet\" (para datos MEG usando redes neuronales). </td></tr>\n","  <tr><th colspan=\"1\">Objetos que retorna la función</th><th colspan=\"1\" align=\"left\">Descripción</th></tr>\n","  <tr><td>component_dict</td><td>Diccionario con las llaves \"y_pred_probs\" para acceder a los valores de probabilidades y la clave \"labels\" para acceder a los valores de las etiquetas.</td></tr>\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_boUXMoscxX"},"outputs":[],"source":["#ICLabel\n","ic_labels = mne_icalabel.label_components(\n","    single_test_sub,\n","    ica,\n","    method=\"iclabel\"\n","    )\n","\n","labels = ic_labels[\"labels\"] #obtenemos las \"labels\" o descripciones de los componentes.\n","probs = ic_labels[\"y_pred_proba\"] #obtenemos las probabilidades de cada label.\n","exclude_idx = [\n","    idx for idx, (label, prob) in enumerate(zip(labels, probs))\n","    if label not in [\"brain\", \"other\"] and prob > 0.9 #seleccionamos las labels, y solamente las agregamos si tienen una probabilidad de 0.9\n","    ]\n","\n","print(labels)\n","print(probs)"]},{"cell_type":"markdown","metadata":{"id":"vcbjP-VFzr4k"},"source":["Recuperemos la información del objeto ica del participante 23 ya con el atributo `.exclude` modificado con los índices de los componentes que estas herramientas encontraron."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"W868nyn5GTRy"},"outputs":[],"source":["#@title Black Box_(soluciones con etiquetas/labels)\n","%%capture\n","!wget \"https://drive.usercontent.google.com/download?id=1kkSuLnF7luEdztVXgjxSHpimmCPHwMmn&export=download&confirm\" -O labeled.zip\n","!unzip -o labeled.zip -d /content/\n","ica_labeled = mne.preprocessing.read_ica(\"./objects_labeled/23_ica.fif\")"]},{"cell_type":"markdown","source":["Utilizaremos entonces los atributos `.labels` y `.exclude` de los objetos ICA. Estas no son funciones ni métodos, sino características de los objetos. Por su forma de invocarlos, podríamos entenderlos como métodos, mas en la       <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      documentación</a> los encontraremos en el apartado de atributos\n","\n"],"metadata":{"id":"-u3Rpcuq6UwV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdkbEyqLbm4Y"},"outputs":[],"source":["display(ica_labeled.labels_)"]},{"cell_type":"code","source":["display(ica_labeled.exclude)"],"metadata":{"id":"Zzk_F_XY6PT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmVk3zef0ecZ"},"source":["Podemos ver que la lista está con 6 componentes artefactuales.\n","\n","<br>\n","\n","Antes de aplicar el mapa sobre los datos reales, recordemos que se recomienda que estos estén en la misma referencia y rango que los datos entrenados. Intentemos con los datos del participante 23. Referenciemos al common average, computemos sus dimensiones y apliquemos el método `.plot_overlay` para hacer que el mapa ICA nos muestre un gráfico con la señal reconstruida.\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.plot_overlay</strong></strong>\n","  </strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.plot_overlay\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","<br>\n","<tr><td>inst</td><td>La data eeg para estimar cómo sería el mapa aplicado. Aquí irá la señal final a la que planeamos aplicar. </td></tr>\n","<tr><td>exclude</td><td>Índice o lista de índices de componentes que se quieren excluir en la estimación. Aquí irá \"ica_labeled.exclude\", es decir, la lista .exclude de nuestro nuevo objeto ICA. </td></tr>\n","<tr><td>picks</td><td>Tipo de canales para aplicar la transformación. Es buena práctica delimitarlo ('eeg' en nuestro caso) </td></tr>\n","\n","<tr><td>n_pca_components</td><td>Número de componentes para proyectar. Se recomienda siempre proyectar tantos componentes como dimensiones tienen nuestros datos. Como los datos son copias, los valores de la señal de los componentes artefactuales se proyectarán de tal manera que sean anulados (\"0\"), desapareciendo así de la señal. </td></tr>\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Figura con la señal reconstruida del objeto EEG. Si el mapa tiene componentes excluidos/tachados, su señal se anulará al ser proyectada.\n","</table>"]},{"cell_type":"code","source":["#Aplicamos la referencia de 'average' para igualar\n","subject_to_apply=filtered_eeg['23'].set_eeg_reference('average')"],"metadata":{"id":"pPLuOyfFugk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calculamos el rango para saber las dimensiones\n","rank_to_apply_dictionary=mne.compute_rank(subject_to_apply)\n","rank_to_apply=rank_to_apply_dictionary['eeg']"],"metadata":{"id":"LXbWRQEbuncr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEBgHIcKHjkS"},"outputs":[],"source":["graph1=ica_labeled.plot_overlay(\n","                 inst=subject_to_apply,\n","                 exclude=ica_labeled.exclude,\n","                 picks='eeg',\n","                 n_pca_components=rank_to_apply\n","                 )"]},{"cell_type":"markdown","metadata":{"id":"gm8koT9x8voq"},"source":["Vemos que la señal se limpia bastante luego del ICA (la señal roja es la anterior, la que está de negro es la nueva), pero no completamente.\n","\n","<br>\n","\n","Hoy en día, se utiliza los métodos automáticos de ICA junto a la inspección manual de componentes. La tendencia es ir reduciendo la intervención humana para mejorar la replicabilidad (es difícil replicar sesgos al seleccionar componentes).\n","\n","<br>\n","\n","De hecho, en los estudios con muchos participantes, se optan por pipelines completamente automáticos pues es imposible revisar cada participante.\n","\n","<br>\n","\n","La última fase del ICA es el aplicarla finalmente a la señal. Antes estábamos viendo \"cómo se veía\" al aplicarla, para saber si excluir o no más componentes antes de aplicarla. Ahora, con el método `.apply`, se proyectarán los componentes y se reconstruirá la señal.\n","\n","<br>\n","\n","<table>\n","  <tr><th colspan=\"2\" align=\"left\">Método: <strong>.apply</strong></strong>\n","  </strong>\n","  <br><br>\n","  Objeto mne.preprocessing.ICA</strong>\n","  </strong>\n","      <a href=\"https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.apply\"\n","       target=\"_blank\" rel=\"noopener\" style=\"margin-left:.5rem; font-weight:normal;\">\n","      [docs]\n","  </a>\n","\n","  \n","  </th></tr>\n","\n","<br>\n","<tr><td>inst</td><td>La data eeg para reconstruir. </td></tr>\n","<tr><td>exclude</td><td>Lista de componentes que serán proyectados como anulados (\"zeroed out\"). </td></tr>\n","<tr><td>n_pca_components</td><td>Número de componentes para proyectar. El mismo que las dimensiones de nuestra señal objetivo. </td></tr>\n","\n","<tr><th colspan=\"2\" align=\"left\">Objetos que retorna:</th></tr>\n","\n","<td colspan=\"2\">\n","Objeto EEG/'Raw' con la señal procesada.\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZMni0of_SMi"},"outputs":[],"source":["#Probemos aplicando el objeto ica_labeled\n","final_copy=subject_to_apply.copy() #siempre es buena idea hacer una copia de la señal antes de aplicar la solución.\n","\n","clean_signal=ica_labeled.apply(\n","                 inst=final_copy,\n","                 exclude=ica_labeled.exclude,\n","                 n_pca_components=rank_to_apply\n","                 )"]},{"cell_type":"markdown","source":["Por último, podríamos utilizar el método `plot`, como en el principio, pero esta vez para ver el cambio de señales."],"metadata":{"id":"h6mZBHQk5aHU"}},{"cell_type":"code","source":["graph1=original_eeg['23'].plot()\n","graph2=final_copy.plot()"],"metadata":{"id":"5uWY-V0r0rDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2> Flujo general </h2>\n","\n","¡Ya está! Hemos terminado el primer tutorial, a grandes rasgos, podemos ver que hicimos lo siguiente:\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_06.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Flujo paso por paso.</figcaption>\n","</figure>\n","\n","\n","\n","\n","<br>\n","\n","\n","O, si lo queremos ver en fases, podemos también simplificarlo así:\n","\n","<br>\n","\n","<figure style=\"text-align:left; margin: 1.25rem 0;background:#fff;\">\n","  <img src=\"https://raw.githubusercontent.com/neuropucp/neuroling-workshop/refs/heads/main/res/assets/status_05.png\"\n","       alt=\"vol\"\n","       style=\"display:block; margin:0 auto; max-width:50%; width:600px; height:auto;\">\n","  <figcaption style=\"margin-top:.5rem; color:#555;\">Flujo general.</figcaption>\n","</figure>\n","\n"],"metadata":{"id":"oxKnt4tJdMc6"}},{"cell_type":"markdown","metadata":{"id":"kPXZJqzOAAbq"},"source":["<h2>Código completo para ser ejecutado automáticamente a todos los participantes</h2>\n","\n","Podemos ejecutar todos estos pasos de manera automática en una iteración con cada participante. Ya tenemos los diccionarios `train_eeg`, con los objetos filtrados para entrenar ICA, y `filtered_eeg` con los objetos con nuestros filtros finales."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TERZsPAuA1is"},"outputs":[],"source":["########################\n","#########ICA############\n","########################\n","#Creemos un diccionario para guardar los objetos eeg finales\n","cleaned_eeg={}\n","for sub, eeg in train_eeg.items(): #Iteramos en los datos de entrenamiento.\n","  rank_train_dictionary=mne.compute_rank(eeg)\n","  rank_train=rank_train_dictionary['eeg']\n","\n","  ica = mne.preprocessing.ICA(\n","              n_components=rank_train, #Rank o dimensiones independientes.\n","              method = \"infomax\",  # Método\n","              fit_params = {'extended':True}, #Parámetros del método.\n","              max_iter = \"auto\",\n","              random_state = 7  # Lucky!\n","          )\n","\n","  ica.fit(eeg, picks='eeg') #eeg es por default, pero es buena práctica.\n","\n","  eog_indices, eog_scores = ica.find_bads_eog( #Este es el método.\n","    single_test_sub, #pasamos nuestro set de entrenamiento\n","    ch_name=['HEOG', 'VEOG'],\n","    threshold=3.0,\n","    verbose=False\n","  )\n","\n","  ic_labels = mne_icalabel.label_components(\n","    single_test_sub,\n","    ica,\n","    method=\"iclabel\"\n","    )\n","\n","  labels = ic_labels[\"labels\"] #obtenemos las \"labels\" o descripciones de los componentes.\n","  probs = ic_labels[\"y_pred_proba\"] #obtenemos las probabilidades de cada label.\n","  exclude_idx = [\n","      idx for idx, (label, prob) in enumerate(zip(labels, probs))\n","      if label not in [\"brain\", \"other\"] and prob > 0.9 #seleccionamos las labels, y solamente las agregamos si tienen una probabilidad de 0.9\n","      ]\n","\n","  ica.exclude=list(set(ica.exclude + eog_indices)) #No reemplacemos una lista con otra. Combinémoslas.\n","\n","  #Podemos guardar los objetos si los necesitamos para luego\n","  path=os.path.join(os.getcwd(), f'ica_objects/{sub}')\n","  os.makedirs(path, exist_ok=True)\n","  ica.save(os.path.join(path, f'{sub}_ica.fif'), overwrite=True)\n","\n","  #Obtenemos la información de los objetos a aplicar\n","  eeg_to_apply=filtered_eeg[sub].copy()\n","  eeg_to_apply=eeg_to_apply.set_eeg_reference('average')\n","  rank_final_dictionary=mne.compute_rank(eeg_to_apply)\n","  rank_final=rank_final_dictionary['eeg']\n","\n","  #Aplicamos la solución ICA\n","  eeg_final=ica.apply(\n","      eeg_to_apply,\n","      exclude=ica.exclude,\n","      n_pca_components=rank_final\n","  )\n","  #Guardamos los objetos finales en el diccionario\n","  cleaned_eeg[sub] = eeg_final\n","\n"]},{"cell_type":"markdown","source":["Referencias:\n","\n","\n","> - Gorgolewski, K. J., Auer, T., Calhoun, V. D., Craddock, R. C., Das, S., Duff, E. P., ... & Poldrack, R. A. (2016). The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Scientific data, 3(1), 1-9.\n","\n","> - Isasi-Isasmendi, A., Sauppe, S., Andrews, C., Laka, I., Meyer, M., & Bickel, B. (2024). Incremental sentence processing is guided by a preference for agents: EEG evidence from Basque. Language, Cognition and Neuroscience, 39(1), 76-97.\n","\n","> - Gramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., ... & Hämäläinen, M. (2013). MEG and EEG data analysis with MNE-Python. Frontiers in Neuroinformatics, 7, 267.\n","[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17345411.svg)](https://doi.org/10.5281/zenodo.17345411).\n","\n",">- Isasi-Isasmendi, A., Sauppe, S., Andrews, C., Laka, I., Meyer, M., & Bickel, B. (2024). Incremental sentence processing is guided by a preference for agents: EEG evidence from Basque. Language, Cognition and Neuroscience, 39(1), 76-97.\n","\n","> - Jas, M., Engemann, D. A., Bekhti, Y., Raimondo, F., & Gramfort, A. (2017). Autoreject: Automated artifact rejection for MEG and EEG data. NeuroImage, 159, 417-429.\n","\n","> - Jas, M., Engemann, D., Raimondo, F., Bekhti, Y., & Gramfort, A. (2016, June). Automated rejection and repair of bad trials in MEG/EEG. In 2016 international workshop on pattern recognition in neuroimaging (PRNI) (pp. 1-4). IEEE.\n","\n","> - Appelhoff, S., Hurst, A. J., Lawrence, A., Li, A., Mantilla Ramos, Y. J., O'Reilly, C., ... & Dancker, J. (2022). PyPREP: A Python implementation of the preprocessing pipeline (PREP) for EEG data. Zenodo, 2. [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.16039994.svg)](https://doi.org/10.5281/zenodo.16039994)\n","\n","> - Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K.-M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in Neuroinformatics, 9, 16. doi: 10.3389/fninf.2015.00016\n","\n","> - Mendoza-Halliday, D., Major, A. J., Lee, N., Lichtenfeld, M. J., Carlson, B., Mitchell, B., ... & Bastos, A. M. (2024). A ubiquitous spectrolaminar motif of local field potential power across the primate cortex. Nature Neuroscience, 27(3), 547-560.\n","\n","> - Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., Höchenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A., & Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software, 4:1896. DOI: 10.21105/joss.01896\n","\n","> - Pernet, C. R., Appelhoff, S., Gorgolewski, K. J., Flandin, G., Phillips, C., Delorme, A., & Oostenveld, R. (2019). EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Scientific data, 6(1), 103.\n","\n","> - Newman, A. J. Neural data science in python (2020). URL https://neuraldatascience.io/intro.html.\n","\n","> - Li, A., Feitelberg, J., Saini, A. P., Höchenberger, R., & Scheltienne, M. (2022). MNE-ICALabel: Automatically annotating ICA components with ICLabel in Python. Journal of Open Source Software, 7(76), 4484.\n","\n","> - Pion-Tonachini, L., Kreutz-Delgado, K., & Makeig, S. (2019). ICLabel: An automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198, 181-197.\n","\n","> - Winkler, I., Debener, S., Müller, K. R., & Tangermann, M. (2015, August). On the influence of high-pass filtering on ICA-based artifact reduction in EEG-ERP. In 2015 37th annual international conference of the IEEE engineering in medicine and biology society (EMBC) (pp. 4101-4105). IEEE.\n","\n"],"metadata":{"id":"cde0stHOO1r4"}},{"cell_type":"markdown","source":["Autores:\n","\n","Daniel Falcón.  \n","Renato Paredes."],"metadata":{"id":"VFIT3yzrV0yU"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"neuropucp-book","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.12"}},"nbformat":4,"nbformat_minor":0}